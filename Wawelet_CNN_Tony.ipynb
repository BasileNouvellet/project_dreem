{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "MlTM3BoSt_Du",
    "outputId": "933bcd70-14ab-45e3-da22-67a63c905b87"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split \n",
    "import pywt\n",
    "from plotly import tools\n",
    "from plotly.offline import init_notebook_mode, iplot, plot\n",
    "# import cufflinks as cf\n",
    "import plotly.graph_objs as go\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import warnings\n",
    "import time\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = h5py.File(\"original_data/X_train.h5\", \"r\")\n",
    "y_train_ = pd.read_csv(\"original_data/y_train.csv\").as_matrix()[:, 1].squeeze()\n",
    "df_train = pd.DataFrame(data=X_train[\"features\"][:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_columns(df):\n",
    "    l_columns = ['num_pso', \n",
    "             'mean_amp_pso',\n",
    "             'mean_dur_pso',\n",
    "              'amp_cso',\n",
    "              'dur_cso',\n",
    "              'curr_sleep_stage',\n",
    "              'time_since_sleep',\n",
    "              'time_in_ds',\n",
    "              'time_in_ls',\n",
    "              'time_in_rs',\n",
    "              'time_in_ws']\n",
    "    for i in range(12, 1261+1):\n",
    "        l_columns.append('eeg_signal_%s'%(i-12+1))\n",
    "    df.columns = l_columns\n",
    "\n",
    "    return df\n",
    "df_train=label_columns(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "eegcolumns = ['eeg_signal_%s'%(i-12+1) for i in range(12, 1261+1)]\n",
    "cols=list(df_train.columns)\n",
    "selected_var=[c for c in eegcolumns]\n",
    "\n",
    "X_train_cnn, X_val_cnn, y_train_cnn, y_val_cnn = train_test_split(df_train[selected_var], y_train_, test_size=0.10,random_state=0, stratify=y_train_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "234.02365946769714\n"
     ]
    }
   ],
   "source": [
    "n_image_train=128\n",
    "scales = range(1,1251)\n",
    "start = time.time()\n",
    "Array_images_train=np.ndarray(shape=(n_image_train, 1250, 1250,1))\n",
    "for i in range(0,n_image_train):\n",
    "    Array_images_train[i, :, :,0] = (abs(pywt.cwt(X_train_cnn.iloc[i,:], scales,\"morl\", 1/125)[0]))**2\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "236.86612725257874\n"
     ]
    }
   ],
   "source": [
    "n_image_test=128\n",
    "scales = range(1,1251)\n",
    "start = time.time()\n",
    "Array_images_test=np.ndarray(shape=(n_image_test, 1250, 1250,1))\n",
    "for i in range(0,n_image_test):\n",
    "    Array_images_test[i, :, :,0] = (abs(pywt.cwt(X_val_cnn.iloc[i,:], scales,\"morl\", 1/125)[0]))**2\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = Array_images_train\n",
    "y_train_cnn_cut = y_train_cnn[0:n_image_train]\n",
    "x_test = Array_images_test\n",
    "y_test_cnn_cut = y_val_cnn[0:n_image_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 128 samples, validate on 128 samples\n",
      "Epoch 1/5\n",
      "128/128 [==============================] - 41s 319ms/step - loss: 2865766.8638 - accuracy: 0.4062 - val_loss: 2862329.5469 - val_accuracy: 0.3516\n",
      "Epoch 2/5\n",
      "128/128 [==============================] - 38s 301ms/step - loss: 1866672.7031 - accuracy: 0.4453 - val_loss: 1247174.3359 - val_accuracy: 0.4297\n",
      "Epoch 3/5\n",
      "128/128 [==============================] - 38s 297ms/step - loss: 423290.3867 - accuracy: 0.4766 - val_loss: 1438629.2891 - val_accuracy: 0.2969\n",
      "Epoch 4/5\n",
      "128/128 [==============================] - 38s 297ms/step - loss: 225575.8633 - accuracy: 0.5547 - val_loss: 228301.4648 - val_accuracy: 0.3516\n",
      "Epoch 5/5\n",
      "128/128 [==============================] - 38s 296ms/step - loss: 51973.5015 - accuracy: 0.6328 - val_loss: 76440.0083 - val_accuracy: 0.4375\n",
      "Train loss: 26853.267333984375, Train accuracy: 0.6796875\n",
      "Test loss: 76440.0087890625, Test accuracy: 0.4375\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import History \n",
    "history = History()\n",
    " \n",
    "img_x = 1250\n",
    "img_y = 1250\n",
    "img_z = 1\n",
    "input_shape = (img_x, img_y, img_z)\n",
    " \n",
    "num_classes = 3\n",
    "batch_size = 16\n",
    "epochs = 5\n",
    " \n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "    \n",
    "y_train = keras.utils.to_categorical(y_train_cnn_cut, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test_cnn_cut, num_classes)\n",
    " \n",
    " \n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(4, kernel_size=(5, 5),activation='relu', input_shape=input_shape))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    " \n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test),\n",
    "          callbacks=[history])\n",
    " \n",
    "train_score = model.evaluate(x_train, y_train, verbose=0)\n",
    "print('Train loss: {}, Train accuracy: {}'.format(train_score[0], train_score[1]))\n",
    "test_score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss: {}, Test accuracy: {}'.format(test_score[0], test_score[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
